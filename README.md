# Video Threat Detection

## Phase 1 â€“ Environment Setup & Model Integration (Week 1)

---

## ğŸ“… Timeline

* **Assignment received:** 15 December 2025
* **Phase 1 completion:** 18 December 2025
* **Time taken:** ~3 days

Phase 1 ka kaam assignment milne ke sirf **3 din ke andar** complete kiya gaya.

---

## ğŸ“Œ Project Overview

Is project ka goal ek **AI-powered video threat detection pipeline** banana hai jo:

* Video ko frames me convert kare
* Har frame par detection run kare
* Structured JSON output generate kare
* Aage chal ke Vision-Language Models ke sath scale ho sake

Phase 1 me focus **foundation strong karne** par tha â€” environment, pipeline, structure, aur output format.

---

## ğŸ“ Project Structure

```
video-threat-detection/
â”‚
â”œâ”€â”€ DATA/
â”‚   â”œâ”€â”€ videos/
â”‚   â”‚   â””â”€â”€ sample.mp4
â”‚   â”œâ”€â”€ frames/
â”‚   â”‚   â”œâ”€â”€ frame_0.jpg
â”‚   â”‚   â”œâ”€â”€ frame_1.jpg
â”‚   â”‚   â””â”€â”€ ...
â”‚   â””â”€â”€ output_detections.json
â”‚
â”œâ”€â”€ src/
â”‚   â””â”€â”€ detection/
â”‚       â”œâ”€â”€ frame_extractor.py
â”‚       â”œâ”€â”€ image_loader.py
â”‚       â”œâ”€â”€ person_detector.py
â”‚       â”œâ”€â”€ vlm_detector.py
â”‚       â”œâ”€â”€ vlm_model_load.py
â”‚       â”œâ”€â”€ bbox_utils.py
â”‚       â””â”€â”€ run_video_detection.py
â”‚
â”œâ”€â”€ main.py
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md
```

---

## âœ… Phase 1 â€“ Week 1: Work Completed

### 1ï¸âƒ£ Python Environment Setup

**Status: âœ… Completed**

* Python virtual environment set up
* Required dependencies installed and verified:

  * `torch`
  * `transformers`
  * `opencv-python`
  * `numpy`
* Environment tested using multiple scripts

ğŸ‘‰ Environment related issues resolved early to avoid future blockers.

---

### 2ï¸âƒ£ Vision-Language Model (VLM) Integration

**Status: âœ… Completed (Using Alternative VL SLM)**

Assignment requirement mentioned:

> *Ollama with Qwen2.5-VL model (or alternative VL SLM)*

* **Florence-2 (HuggingFace Transformers)** used as an alternative Vision-Language Model
* Model loading and compatibility tested
* Ollama + Qwen2.5-VL intentionally skipped for now (allowed as per assignment wording)

ğŸ“ **Important Note:**
Florence-2 is currently used to validate pipeline structure.
Real VLM inference will be finalized in Phase 2.

---

### 3ï¸âƒ£ Video Frame Extraction Pipeline

**Status: âœ… Completed**

* Implemented using OpenCV (`frame_extractor.py`)
* Video input taken from `DATA/videos/`
* Frames extracted and saved to `DATA/frames/`
* Frame extraction tested on sample video successfully

ğŸ‘‰ This forms the backbone of the full video pipeline.

---

### 4ï¸âƒ£ VLM Inference Wrapper (Stub-Based)

**Status: âœ… Completed (Phase 1 Scope)**

* Implemented in `vlm_detector.py`
* Stub-based inference used to avoid early model mismatch issues
* Output JSON structure finalized
* Easy to replace stub with real VLM inference later

**Sample Detection Output:**

```json
{
  "image": "DATA/frames/frame_0.jpg",
  "image_size": {
    "width": 1280,
    "height": 720
  },
  "objects": [
    {
      "label": "person",
      "confidence": 0.92,
      "bbox_pixel": {
        "x_min": 128,
        "y_min": 72,
        "x_max": 512,
        "y_max": 576
      }
    }
  ]
}
```

---

### 5ï¸âƒ£ Bounding Box Parsing & Coordinate Normalization

**Status: âœ… Completed**

* Implemented in `bbox_utils.py`
* Normalized bounding boxes converted to absolute pixel coordinates
* Formula used:

```
x_pixel = x_normalized Ã— image_width  
y_pixel = y_normalized Ã— image_height
```

* Verified using 1280Ã—720 frame resolution

---

### 6ï¸âƒ£ End-to-End Phase 1 Deliverable

**Status: âœ… Completed**

âœ”ï¸ Video â†’ Frames pipeline working
âœ”ï¸ Frame-wise detection pipeline working
âœ”ï¸ Structured JSON output generated
âœ”ï¸ Absolute pixel bounding boxes verified

---

## ğŸ“Œ Current Status

* **Phase 1 â€“ Week 1: 100% Complete**
* Codebase is clean, modular, and scalable
* Known model mismatch issues handled safely using stub inference
* Ready for Phase 2 expansion without refactoring

---

## ğŸš€ Next Steps (Phase 2 â€“ Week 2)

* Replace stub inference with real Florence-2 inference
* Add prompt-based object detection
* Improve reasoning and detection quality
* Optional: Integrate Ollama + Qwen2.5-VL

---

## ğŸ§  Final Summary

This repository represents a **fully functional Phase 1 pipeline**, completed within **3 days**, with a strong foundation for future development and real-world Vision-Language Model integration.
